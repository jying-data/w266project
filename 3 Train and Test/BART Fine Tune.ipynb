{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, EarlyStoppingCallback\n",
    "import pickle\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print('GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and tokenizer\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# freeze encoder layers\n",
    "for param in model.base_model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.base_model.shared.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenized training/dev data\n",
    "train_source_tokenized  = torch.load('train_source_tokenized.pt')\n",
    "train_target_tokenized  = torch.load('train_target_tokenized.pt')\n",
    "dev_source_tokenized  = torch.load('dev_source_tokenized.pt')\n",
    "dev_target_tokenized  = torch.load('dev_target_tokenized.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom dataset class for data loading\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, source, target):\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target = {key: val[idx].detach().clone() for key, val in self.target.items()}\n",
    "        target_input_ids = target['input_ids'][:-1].detach().clone()\n",
    "        target_attention_mask = target['attention_mask'][:-1].detach().clone()\n",
    "\n",
    "        labels = target['input_ids'][1:].detach().clone()\n",
    "        labels[labels[:] == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        source = {key: val[idx].detach().clone() for key, val in self.source.items()}\n",
    "        \n",
    "        item = {'input_ids': source['input_ids'].detach().clone(),\n",
    "                'attention_mask': source['attention_mask'].detach().clone(),\n",
    "                'decoder_input_ids': target_input_ids.detach().clone(),\n",
    "                'decoder_attention_mask': target_attention_mask.detach().clone(),\n",
    "                'labels': labels}\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source[\"input_ids\"])\n",
    "\n",
    "train_dataset = CustomDataset(train_source_tokenized, train_target_tokenized)\n",
    "val_dataset = CustomDataset(dev_source_tokenized, dev_target_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='10053' max='25000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10053/25000 3:53:47 < 5:47:40, 0.72 it/s, Epoch 2.01/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.829500</td>\n",
       "      <td>1.773201</td>\n",
       "      <td>671.241800</td>\n",
       "      <td>148.978000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.783000</td>\n",
       "      <td>1.738948</td>\n",
       "      <td>671.427600</td>\n",
       "      <td>148.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.761500</td>\n",
       "      <td>1.719797</td>\n",
       "      <td>666.265700</td>\n",
       "      <td>150.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.746800</td>\n",
       "      <td>1.705974</td>\n",
       "      <td>666.166700</td>\n",
       "      <td>150.113000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.736900</td>\n",
       "      <td>1.695640</td>\n",
       "      <td>666.161400</td>\n",
       "      <td>150.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.639000</td>\n",
       "      <td>1.692161</td>\n",
       "      <td>666.697200</td>\n",
       "      <td>149.993000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.643300</td>\n",
       "      <td>1.687195</td>\n",
       "      <td>668.212000</td>\n",
       "      <td>149.653000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.640200</td>\n",
       "      <td>1.681399</td>\n",
       "      <td>668.934100</td>\n",
       "      <td>149.492000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.637000</td>\n",
       "      <td>1.674053</td>\n",
       "      <td>668.748100</td>\n",
       "      <td>149.533000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.631100</td>\n",
       "      <td>1.671935</td>\n",
       "      <td>666.417200</td>\n",
       "      <td>150.056000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# arguments for Huggingface trainer class\n",
    "args = TrainingArguments(\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=10,\n",
    "    per_device_eval_batch_size=10,\n",
    "    output_dir=\"output\",\n",
    "    save_strategy = \"no\",\n",
    "    metric_for_best_model = 'eval_loss',\n",
    "    load_best_model_at_end=True,\n",
    "    fp16 = True,\n",
    "    evaluation_strategy = \"steps\",\n",
    "    eval_steps=1000,\n",
    "    learning_rate = 1.97622e-05,\n",
    "    weight_decay = 0.0298317,\n",
    "    seed = 21)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience = 2)])\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
